{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb399a92",
   "metadata": {},
   "source": [
    "# Data generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d05cecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Data creation\n",
    "# Generate random sample data for the variables\n",
    "np.random.seed(50)  # For reproducibility\n",
    "\n",
    "num_samples = 100000\n",
    "\n",
    "air_velocity = np.random.uniform(low=0.5, high=2.5, size=num_samples)\n",
    "steam_inlet_temp = np.random.uniform(low=147, high=153, size=num_samples)\n",
    "steam_outlet_temp = np.random.uniform(low=136, high=145, size=num_samples)\n",
    "steam_sep_line_temp = np.random.uniform(low=115, high=125, size=num_samples)\n",
    "transfer_cool_air_temp = np.random.uniform(low=63, high=125, size=num_samples)\n",
    "steam_pressure = np.random.uniform(low=2.6, high=2.8, size=num_samples)\n",
    "ambient_temp = np.random.uniform(low=20, high=40, size=num_samples)\n",
    "feed_rate = np.random.uniform(low=1000, high=2000, size=num_samples)\n",
    "moisture_content = 0.00001*air_velocity + 0.07*steam_inlet_temp + 0.06*steam_outlet_temp + 0.078*steam_sep_line_temp\n",
    "+0.3*transfer_cool_air_temp - 0.004*steam_pressure + 0.09*ambient_temp + 0.007*feed_rate + np.random.uniform(low=-16,high=16)\n",
    "# np.random.uniform(low=4.5, high=6.5, size=num_samples)\n",
    "\n",
    "# Rescale the moisture values to the desired range\n",
    "moisture_content = 4.5 + (moisture_content - np.min(moisture_content))*(6.5 - 4.5) / (np.max(moisture_content) - np.min(moisture_content))\n",
    "\n",
    "# Combine the variables into a dataframe\n",
    "data = pd.DataFrame({\n",
    "    'Air Velocity': air_velocity,\n",
    "    'Steam Inlet Temp': steam_inlet_temp,\n",
    "    'Steam Outlet Temp': steam_outlet_temp,\n",
    "    'Steam Sep Line Temp': steam_sep_line_temp,\n",
    "    'Transfer cool air temp':transfer_cool_air_temp,\n",
    "    'Steam Pressure': steam_pressure,\n",
    "    'Ambient Temp': ambient_temp,\n",
    "    'Feed_rate':feed_rate,\n",
    "    'Moisture Content': moisture_content\n",
    "})\n",
    "data.to_csv(r'C:\\Users\\Harshita.Saxena\\Downloads\\Meta_San_Simulator\\sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4af06f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Load the data from a CSV file into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(filename)\n",
    "    return data\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Preprocess the data, including handling missing values, outliers, and transforming variables.\n",
    "    \"\"\"\n",
    "    # Example code for handling missing values\n",
    "    # data = data.dropna()\n",
    "\n",
    "    # Example code for log transformation\n",
    "    # data['column'] = np.log(data['column'])\n",
    "\n",
    "    return data\n",
    "\n",
    "def split_data(data, target_column, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets.\n",
    "    \"\"\"\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def standardize_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Standardize/Normalize the data.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "def build_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Build a linear regression model and train it on the training data.\n",
    "    \"\"\"\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "     #Get the coefficients and intercept of the linear regression model\n",
    "    coefficients = model.coef_\n",
    "    intercept = model.intercept_\n",
    "\n",
    "    # Print the predicted equation\n",
    "    equation = \"Moisture Content = {:.5f} + ({:.5f} * Air Velocity) + ({:.5f} * Steam Inlet Temp) + ({:.5f} * Steam Outlet Temp) + ({:.5f} * Steam Sep Line Temp) + ({:.5f} * Steam Pressure) + ({:.5f} * Transfer Cool Air Temp) +({:.5f} * Ambient Temp)+({:.5f} * Feed Rate))\".format(\n",
    "        intercept, coefficients[0], coefficients[1], coefficients[2], coefficients[3], coefficients[4] , coefficients[5],coefficients[6],coefficients[7]\n",
    "    )\n",
    "    print(\"Predicted Equation:\\n\", equation)\n",
    "\n",
    "    return model , coefficients , intercept\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the training and testing data.\n",
    "    \"\"\"\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    #print(model.summary())\n",
    "    return train_mse, test_mse, train_r2, test_r2\n",
    "\n",
    "def make_predictions(model, scaler, data):\n",
    "    \"\"\"\n",
    "    Use the trained model to make predictions on new/unseen data.\n",
    "    \"\"\"\n",
    "    new_data_scaled = scaler.transform(data)\n",
    "    predictions = model.predict(new_data_scaled)\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7972b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Equation:\n",
      " Moisture Content = 5.49526 + (-0.00000 * Air Velocity) + (0.00001 * Steam Inlet Temp) + (0.14362 * Steam Outlet Temp) + (0.18382 * Steam Sep Line Temp) + (0.26569 * Steam Pressure) + (0.00000 * Transfer Cool Air Temp) +(-0.00000 * Ambient Temp)+(-0.00000 * Feed Rate))\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the problem and load the data\n",
    "data = load_data(r'C:\\Users\\Harshita.Saxena\\Downloads\\Meta_San_Simulator\\sample_data.csv')\n",
    "\n",
    "# Step 2: Explore the data\n",
    "# Perform EDA and check the structure, missing values, outliers, etc.\n",
    "\n",
    "# Step 3: Preprocess the data\n",
    "data = preprocess_data(data)\n",
    "\n",
    "# Step 4: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = split_data(data, 'Moisture Content')\n",
    "\n",
    "# Step 5: Standardize/Normalize the data\n",
    "X_train_scaled, X_test_scaled, scaler = standardize_data(X_train, X_test)\n",
    "\n",
    "# Step 6: Build the linear regression model\n",
    "model , coefficients , intercept = build_model(X_train_scaled, y_train)\n",
    "\n",
    "# Step 7: Model evaluation\n",
    "train_mse, test_mse, train_r2, test_r2 = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5124df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upper and lower bounds\n",
    "ub_lb_df = pd.DataFrame( { 'Controllable_Parameter' :['Steam Inlet Temp' ,'Steam Outlet Temp','Steam Sep Line Temp','Transfer cool air temp'],\n",
    "                          'lower' : [147 , 136 , 115 ,63 ] , \n",
    "                          'upper': [153 , 145 , 125 , 125] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "153bbe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_dict = {'model': model,'coeffecients':coefficients,'intercept':intercept, 'ub_lb_df':ub_lb_df}\n",
    "model_dict\n",
    "\n",
    "model_file = \"LOD_prediction_training.pkl\"\n",
    "with open(model_file, 'wb') as file:  \n",
    "    pickle.dump(model_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
