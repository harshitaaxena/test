{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513b30ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:28:38) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c55456",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b34b0d50",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyarrow.lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29252\\2692315118.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit_chat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\openai\\lib\\site-packages\\streamlit\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_STREAMLIT_VERSION_STRING\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeltaGenerator\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_DeltaGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRootContainer_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRootContainer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_RootContainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m from streamlit.runtime.caching import (\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\openai\\lib\\site-packages\\streamlit\\delta_generator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFinal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_util\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_util\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCursor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melements\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAlertMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\openai\\lib\\site-packages\\streamlit\\cursor.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscriptrunner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_script_run_ctx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\openai\\lib\\site-packages\\streamlit\\runtime\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Explicitly re-export public symbols from runtime.py and session_manager.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRuntime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mRuntime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRuntimeConfig\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mRuntimeConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRuntimeState\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mRuntimeState\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\openai\\lib\\site-packages\\streamlit\\runtime\\runtime.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBackMsg_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBackMsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mForwardMsg_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mForwardMsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp_session\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAppSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m from streamlit.runtime.caching import (\n\u001b[0;32m     33\u001b[0m     \u001b[0mget_data_cache_stats_provider\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\openai\\lib\\site-packages\\streamlit\\runtime\\app_session.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPagesChanged_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPagesChanged\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcaching\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlegacy_caching\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCredentials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_msg_queue\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mForwardMsgQueue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\openai\\lib\\site-packages\\streamlit\\runtime\\caching\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBlock_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBlock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m from streamlit.runtime.caching.cache_data_api import (\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mCACHE_DATA_MESSAGE_REPLAY_CTX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mCacheDataAPI\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\openai\\lib\\site-packages\\streamlit\\runtime\\caching\\cache_data_api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStreamlitAPIException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_logger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaching\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_errors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCacheError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCacheKeyNotFoundError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaching\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_type\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCacheType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m from streamlit.runtime.caching.cache_utils import (\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\openai\\lib\\site-packages\\streamlit\\runtime\\caching\\cache_errors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtype_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m from streamlit.errors import (\n\u001b[0;32m     20\u001b[0m     \u001b[0mMarkdownFormattedException\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\openai\\lib\\site-packages\\streamlit\\type_util.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minfer_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\openai\\lib\\site-packages\\pyarrow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0m_gc_enabled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_gc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misenabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0m_gc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_gc_enabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0m_gc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyarrow.lib'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import base64\n",
    "import re\n",
    "import time\n",
    "from io import BytesIO\n",
    "from typing import Any, Dict, List\n",
    "from gtts import gTTS\n",
    "import openai\n",
    "from langchain import LLMChain, OpenAI\n",
    "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent ,create_pandas_dataframe_agent\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import VectorStore\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from pypdf import PdfReader\n",
    "\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "st.set_option('deprecation.showPyplotGlobalUse', False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a60a6e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 04:05:17.775 No runtime found, using MemoryCacheStorageManager\n",
      "2023-06-30 04:05:17.783 No runtime found, using MemoryCacheStorageManager\n",
      "2023-06-30 04:05:17.790 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "# Define a function to parse a PDF file and extract its text content\n",
    "@st.cache_data\n",
    "def parse_pdf(file: BytesIO) -> List[str]:\n",
    "    pdf = PdfReader(file)\n",
    "    output = []\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        # Merge hyphenated words\n",
    "        text = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", text)\n",
    "        # Fix newlines in the middle of sentences\n",
    "        text = re.sub(r\"(?<!\\n\\s)\\n(?!\\s\\n)\", \" \", text.strip())\n",
    "        # Remove multiple newlines\n",
    "        text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text)\n",
    "        output.append(text)\n",
    "    return output\n",
    "\n",
    "\n",
    "# Define a function to convert text content to a list of documents\n",
    "@st.cache_data\n",
    "def text_to_docs(text: str) -> List[Document]:\n",
    "    \"\"\"Converts a string or list of strings to a list of Documents\n",
    "    with metadata.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Take a single string as one page\n",
    "        text = [text]\n",
    "    page_docs = [Document(page_content=page) for page in text]\n",
    "\n",
    "    # Add page numbers as metadata\n",
    "    for i, doc in enumerate(page_docs):\n",
    "        doc.metadata[\"page\"] = i + 1\n",
    "\n",
    "    # Split pages into chunks\n",
    "    doc_chunks = []\n",
    "\n",
    "    for doc in page_docs:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=2000,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "            chunk_overlap=0,\n",
    "        )\n",
    "        chunks = text_splitter.split_text(doc.page_content)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            doc = Document(\n",
    "                page_content=chunk, metadata={\"page\": doc.metadata[\"page\"], \"chunk\": i}\n",
    "            )\n",
    "            # Add sources a metadata\n",
    "            doc.metadata[\"source\"] = f\"{doc.metadata['page']}-{doc.metadata['chunk']}\"\n",
    "            doc_chunks.append(doc)\n",
    "    return doc_chunks\n",
    "\n",
    "\n",
    "# Define a function for the embeddings\n",
    "@st.cache_data\n",
    "def test_embed():\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=api)\n",
    "    # Indexing\n",
    "    # Save in a Vector DB\n",
    "    with st.spinner(\"Document Processing\"):\n",
    "        index = FAISS.from_documents(pages, embeddings)\n",
    "    st.success(\"Processing Completed\", icon=\"âœ…\")\n",
    "    return index\n",
    "\n",
    "\n",
    "# Set up the Streamlit app\n",
    "#st.title(\"ðŸ¤– Converse with your Training Document !! ðŸ§  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d75a8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heuristic logic\n",
    "def reccomendation_generator(input_data,ub_lb_df,coefficients,intercept,predicted_moisture_content,min_,max_):\n",
    "    \n",
    "    '''The function takes as input user entered data for controllable parameters and min and max LOD ranges ,\n",
    "    predicts LOD levels and recommends parameters to reach target LODs\n",
    "    Input :\n",
    "    input_data : DataFrame containing user input of controllable params , external params and fixed params\n",
    "    coefficients : regression coeffs\n",
    "    intercept : Regression intercept\n",
    "    predicted_moisture = LOD prediction given user input\n",
    "    min_ = Minimum allowed LOD as per user input\n",
    "    max_ = Maximum allowed LOD as per user input\n",
    "    \n",
    "    Output :\n",
    "    reccomendation_df : reccommended parameters value in each iteration'''\n",
    "    rec = pd.DataFrame()\n",
    "    input_data_init =input_data.copy()\n",
    "    input_data_init['Iteration'] = 0\n",
    "    input_data_init['LOD_achieved'] =round(predicted_moisture_content[0],2)\n",
    "\n",
    "    coefficients_dict = dict(zip(list(input_data.columns),list(np.append(coefficients,[intercept]))))\n",
    "    # List of keys to include in the subset\n",
    "    controllable_params = ['Steam Inlet Temp', 'Steam Outlet Temp', 'Steam Sep Line Temp' , 'Transfer cool air temp','Transfer Air']\n",
    "\n",
    "    # Subset the dictionary based on the keys\n",
    "    controllable_params_dict = {key: coefficients_dict[key] for key in controllable_params if key in coefficients_dict}\n",
    "    # Sort the dictionary items based on the absolute value of coefficients in increasing order\n",
    "    sorted_coefficients = sorted(controllable_params_dict.items(), key=lambda x: abs(x[1]),reverse=True)\n",
    "\n",
    "    # Create a new dictionary with sorted variable names and coefficients\n",
    "    sorted_coefficients_dict = {k: v for k, v in sorted_coefficients}\n",
    "    #print(sorted_coefficients_dict)\n",
    "\n",
    "    # Convert values to lists\n",
    "    coefficients_dict = {key: [value] for key, value in coefficients_dict.items()}\n",
    "    coefficients_df = pd.DataFrame(coefficients_dict)\n",
    "    if (predicted_moisture_content[0] < min_):\n",
    "        reqd_moisture_list = list(np.arange(round(predicted_moisture_content[0],2)+(max_-min_)/2,round(min_+ (max_-min_)/2,2),(max_-min_)/2))\n",
    "        input_data_init['Step Wise Target LOD Values'] = reqd_moisture_list[0]\n",
    "    elif (predicted_moisture_content[0] > max_) :\n",
    "        reqd_moisture_list = list(np.arange(round(min_+(max_-min_)/2,2),round(predicted_moisture_content[0]+(max_-min_)/2,2),(max_-min_)/2))[::-1]\n",
    "        input_data_init['Step Wise Target LOD Values'] = reqd_moisture_list[0]\n",
    "    else :\n",
    "        reqd_moisture_list = 'None'       \n",
    "        input_data_init['Step Wise Target LOD Values'] = predicted_moisture_content[0]\n",
    "    input_data1 = pd.DataFrame()    \n",
    "    if  reqd_moisture_list!= 'None':\n",
    "        reccommendation_df = pd.DataFrame()\n",
    "        i = 0 \n",
    "        iteration = []\n",
    "        for y in reqd_moisture_list:\n",
    "            i += 1 \n",
    "            reqd_moisture_content = y\n",
    "            recc = pd.DataFrame()\n",
    "            var_list = []\n",
    "            recc_list = []\n",
    "            lod_acheived = []\n",
    "            lod_adjusted = []\n",
    "            iteration = []\n",
    "            for x in sorted_coefficients_dict.keys():\n",
    "                iteration = iteration + [i]\n",
    "                lod_adjusted = lod_adjusted + [reqd_moisture_content]\n",
    "                input_data = input_data.copy()\n",
    "                input_data_ = input_data.drop([x],axis=1)\n",
    "                for a in ['Iteration','Step Wise Target LOD Values','LOD_achieved']:\n",
    "                    if a in list(input_data_.columns):\n",
    "                        input_data_ = input_data_.drop(a,axis=1)    \n",
    "                coefficients_ = coefficients_df.drop(x,axis=1)\n",
    "                coeff_curr = coefficients_df.loc[0,x]\n",
    "                adj_value = (reqd_moisture_content - np.dot(np.array(input_data_),np.array(coefficients_)[0]))/coeff_curr\n",
    "                #print(x)\n",
    "                #print(adj_value)\n",
    "                if adj_value <= float(ub_lb_df[ub_lb_df['Controllable_Parameter']==x].lower):\n",
    "                    adj_value = float(ub_lb_df[ub_lb_df['Controllable_Parameter']==x].lower)\n",
    "                elif adj_value >= float(ub_lb_df[ub_lb_df['Controllable_Parameter']==x].upper):\n",
    "                    adj_value = float(ub_lb_df[ub_lb_df['Controllable_Parameter']==x].upper)\n",
    "                else :\n",
    "                    adj_value = adj_value[0]\n",
    "                input_data[x] = adj_value\n",
    "                #print(input_data)\n",
    "                input_data_copy = input_data.copy()\n",
    "                for b in ['Iteration','Step Wise Target LOD Values','LOD_achieved']:\n",
    "                    if b in list(input_data_copy.columns):\n",
    "                        input_data_copy= input_data_copy.drop(b,axis=1)\n",
    "                updated_lod = np.dot(np.array(input_data_copy),np.array(coefficients_df)[0])[0]\n",
    "                input_data['LOD_achieved'] = updated_lod\n",
    "                input_data['Step Wise Target LOD Values'] = reqd_moisture_content\n",
    "                input_data['Iteration']= i\n",
    "                #print(input_data)\n",
    "                lod_acheived = lod_acheived + [updated_lod]\n",
    "                var_list = var_list + [x]\n",
    "                recc_list = recc_list + [adj_value]\n",
    "                #print(adj_value)\n",
    "                df_ = pd.DataFrame({'Iteration':iteration,'Step Wise Target LOD Values': lod_adjusted,\n",
    "                           'Parameter':var_list, 'Reccomended Value(In Range)': recc_list,'LOD_achieved':lod_acheived})\n",
    "                #print(df_)\n",
    "                input_data1 = pd.concat([input_data1,input_data],ignore_index=True)\n",
    "            reccommendation_df=  pd.concat([reccommendation_df,df_], ignore_index=True)\n",
    "            #print(reccommendation_df)\n",
    "        input_data_f = pd.concat([input_data_init,input_data1], ignore_index= True)\n",
    "        print(\"Maximum Convergence Limit Reached\")\n",
    "        input_data_f= input_data_f.round(4)\n",
    "        repeating_rows = input_data_f['LOD_achieved'] == input_data_f['LOD_achieved'].shift()\n",
    "        # Delete the repeating rows from the DataFrame\n",
    "        # rec = input_data_f[~repeating_rows]\n",
    "        rec = input_data_f.copy()\n",
    "        rec = rec[['Iteration','LOD_achieved','Steam Inlet Temp','Steam Outlet Temp','Steam Sep Line Temp',\n",
    "                   'Transfer cool air temp','Transfer Air','Air Velocity','Steam Pressure','Feed_rate','Ambient Temp','Ambient Humidity',\n",
    "                   'LOD_raw','Swell_vol','on_30','thru_70','thru_100']]\n",
    "        rec.columns = ['Iteration','Updated LOD % ','Steam In Temp (C)','Steam Out Temp (C)','Steam Sep (C)',\n",
    "                   'Cooling Air (C)','Transfer Air (C)','Steam Velocity (m/s)','Steam Pressure (bar)','Feed_rate (kg/hr)','Ambient Temp (F)','Ambient Humidity (%)',\n",
    "                   'Raw Husk LOD (%)','Swell volume(ml)','% on 30','% thru70','% thru 100']\n",
    "        rec=rec.round(decimals = 2)\n",
    "        rec = rec.drop_duplicates()\n",
    "        rec['Iteration']= (rec['Updated LOD % '].diff() != 0).cumsum() - 1\n",
    "        #rec['Iteration']=np.arange(0,len(rec))\n",
    "        rec =rec[['Iteration','Updated LOD % ','Steam In Temp (C)','Steam Out Temp (C)','Steam Sep (C)',\n",
    "                   'Cooling Air (C)','Transfer Air (C)','Steam Velocity (m/s)','Steam Pressure (bar)','Feed_rate (kg/hr)','Ambient Temp (F)','Ambient Humidity (%)',\n",
    "                   'Raw Husk LOD (%)','Swell volume(ml)','% on 30','% thru70','% thru 100']]\n",
    "        rec = rec.reset_index().drop('index',axis=1)\n",
    "        rec1 = rec[['Iteration','Updated LOD % ','Steam In Temp (C)','Steam Out Temp (C)','Steam Sep (C)',\n",
    "                   'Cooling Air (C)','Transfer Air (C)']]\n",
    "        rec1 = rec1.round(decimals = 2)\n",
    "        r1 = pd.DataFrame()\n",
    "        for x in list(rec['Iteration'].unique()):\n",
    "            recc_df_x=rec[rec.Iteration==x]\n",
    "            r = recc_df_x.iloc[-1].to_frame().transpose()\n",
    "            r1 =pd.concat([r1,r],ignore_index=True)\n",
    "    else :\n",
    "        print(\"No Recommendation required\")\n",
    "        rec1 = pd.DataFrame()\n",
    "        rec = pd.DataFrame()\n",
    "    return  rec1 , r1\n",
    "\n",
    "\n",
    "\n",
    "def sensitivity_graph(data, input_data_, coefficients, intercept, ub_lb_df, p):\n",
    "    coefficients_dict = dict(zip(list(input_data_.columns), list(np.append(coefficients, [intercept]))))\n",
    "    # Convert values to lists\n",
    "    coefficients_dict = {key: [value] for key, value in coefficients_dict.items()}\n",
    "    coefficients_df = pd.DataFrame(coefficients_dict)\n",
    "    a = np.dot(np.array(input_data_.drop(p, axis=1))[0], np.array(coefficients_df.drop(p, axis=1))[0])\n",
    "    slope = float(coefficients_df[p])\n",
    "    intercept = float(a)\n",
    "\n",
    "    # Define the equation\n",
    "    def equation(x, slope, intercept):\n",
    "        return intercept + slope * x\n",
    "\n",
    "    x = np.arange(int(ub_lb_df[ub_lb_df['Controllable_Parameter'] == p].lower),\n",
    "                  int(ub_lb_df[ub_lb_df['Controllable_Parameter'] == p].upper), 0.1)\n",
    "    y = equation(x, slope, intercept)\n",
    "\n",
    "    # Dynamic user input for x\n",
    "    user_x = float(input_data_[p])\n",
    "    # Calculate y for the user input x\n",
    "    user_y = equation(user_x, slope, intercept)\n",
    "\n",
    "    # Plot the equation\n",
    "    # Plot the user input point\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(user_x, user_y, 'ro')  # 'ro' for red circles\n",
    "    ax.annotate(f'({round(user_x, 2)}, {round(user_y, 2)})', (user_x, user_y), xytext=(-25, 15),\n",
    "                textcoords='offset points', arrowprops=dict(arrowstyle='->'))\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    if p =='Air Velocity':\n",
    "        ax.set_xlabel('Steam Velocity (m/s)')\n",
    "    elif p=='Steam Inlet Temp':\n",
    "        ax.set_xlabel('Steam Inlet Temp (C)')\n",
    "    elif p== 'Steam Outlet Temp':\n",
    "         ax.set_xlabel('Steam Outlet Temp (C)')\n",
    "    elif p== 'Steam Sep Line Temp':\n",
    "         ax.set_xlabel('Steam Sep Line Temp (C)')\n",
    "    elif p== 'Transfer cool air temp':\n",
    "        ax.set_xlabel('Cool Air (C)')\n",
    "    elif p== 'Transfer Air':\n",
    "        ax.set_xlabel('Transfer Air (C)')\n",
    "    elif p== 'Steam Pressure':\n",
    "        ax.set_xlabel('Steam Pressure (bar)')\n",
    "    elif p== 'Ambient Temp':\n",
    "        ax.set_xlabel('Ambient Temp (F)')\n",
    "    elif p== 'Ambient Humidity':\n",
    "        ax.set_xlabel('Ambient Humidity (%)')\n",
    "    elif p== 'Feed_rate':\n",
    "        ax.set_xlabel('Feed Rate (kg/hr)')\n",
    "    elif p== 'LOD_raw':\n",
    "        ax.set_xlabel('Raw Husk LOD %')\n",
    "    elif p== 'Swell_vol':\n",
    "        ax.set_xlabel('Swell Volume (ml)')\n",
    "    elif p== 'on_30':\n",
    "        ax.set_xlabel('% on 30 mesh')\n",
    "    elif p== 'thru_70':\n",
    "        ax.set_xlabel('% thru 70 mesh')\n",
    "    else:\n",
    "        ax.set_xlabel('% thru 100 mesh')\n",
    "        \n",
    "    ax.set_ylabel('LOD %')\n",
    "    ax.grid(True)\n",
    "    st.pyplot(fig)\n",
    "    \n",
    "\n",
    "\n",
    "def alerts(number,target_min,target_max):\n",
    "    if number < target_min or number > target_max:\n",
    "#         st.markdown('<p style=\"font-weight:bold; color:red; animation: blink 1s infinite;\">'\n",
    "#                     f'<i class=\"fas fa-exclamation-triangle\"></i> {number}</p>', unsafe_allow_html=True)\n",
    "        st.error('Outside Specified Range : '+str(target_min)+'-'+str(target_max))\n",
    "\n",
    "def format_excel(df): \n",
    "    change_description = [''] * len(df)  # Blank entries for all rows\n",
    "    previous_values = {}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        variable_changes = []\n",
    "\n",
    "        for column in ['Steam In Temp (C)','Steam Out Temp (C)','Steam Sep (C)',\n",
    "                   'Cooling Air (C)','Transfer Air (C)']:\n",
    "            if column not in previous_values:\n",
    "                previous_values[column] = row[column]\n",
    "            elif row[column] > previous_values[column]:\n",
    "                change = round(row[column] - previous_values[column], 2)\n",
    "                variable_changes.append(f\"Increase {column} by {change} Degree C\")\n",
    "                previous_values[column] = row[column]\n",
    "            elif row[column] < previous_values[column]:\n",
    "                change = round(previous_values[column] - row[column], 2)\n",
    "                variable_changes.append(f\"Decrease {column} by {change} Degree C\")\n",
    "                previous_values[column] = row[column]\n",
    "\n",
    "        change_description[index] = ', '.join(variable_changes)\n",
    "\n",
    "    df['Change Description'] = change_description\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce64b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = r\"C:\\Users\\Harshita.Saxena\\Downloads\\png_test\\test\\LOD_prediction_training.pkl\" #read model parameters\n",
    "with open(model_file, 'rb') as file:  \n",
    "        parameters = pickle.load(file)\n",
    "coefficients = parameters['coeffecients']\n",
    "intercept= parameters['intercept']\n",
    "ub_lb_df = parameters['ub_lb_df']\n",
    "ub_lb_df_ = pd.DataFrame({'Controllable_Parameter': ['Air Velocity','Steam Pressure','Feed_rate','Ambient Temp','Ambient Humidity','LOD_raw','Swell_vol','on_30','thru_70','thru_100'] ,\n",
    "                          'lower':[29,1,1000,10,10,5,23,23,0,0 ],\n",
    "                         'upper':[32,3,2000,60,60,15,35,60,7,2]})\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\Harshita.Saxena\\Downloads\\png_test\\test\\sample_data.csv') #read sample data\n",
    "data= data[[ 'Air Velocity', 'Steam Inlet Temp', 'Steam Outlet Temp',\n",
    "    'Steam Sep Line Temp', 'Transfer cool air temp', 'Steam Pressure',\n",
    "    'Ambient Temp', 'Ambient Humidity', 'Feed_rate', 'LOD_raw', 'Swell_vol',\n",
    "    'on_30', 'thru_70', 'thru_100','Transfer Air', 'Moisture Content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21752e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#streamlit app \n",
    "# Define page names\n",
    "PAGE_1 =  \"Training Manual\"\n",
    "PAGE_2 =  \"Simulator\"\n",
    "\n",
    "# Create navigation buttons\n",
    "st.set_page_config(page_title=\"Operator Training Application\",layout=\"wide\")\n",
    "nav_option = st.sidebar.radio(\"Operator Training Application\", (PAGE_1, PAGE_2 ))\n",
    "\n",
    "# Display content based on selected page\n",
    "if nav_option == PAGE_1:\n",
    "    st.title(\"Traning Manual\")\n",
    "    st.markdown(\n",
    "    \"\"\" \n",
    "        ####  ðŸ—¨ï¸ Chat with your Training Document ðŸ“œ  \n",
    "        > *powered by [LangChain]('https://langchain.readthedocs.io/en/latest/modules/memory.html#memory') + \n",
    "        [OpenAI]('https://platform.openai.com/docs/models/gpt-3-5')\n",
    "        ----\n",
    "        \"\"\"\n",
    "    )\n",
    "    # Set up the sidebar\n",
    "    sound_file = BytesIO()\n",
    "    text =\"Hello I am your AI powered Training Assistant. Please Upload your Training Document ,Enter your key and i shall provide answers to your queries !!\"\n",
    "    tts = gTTS(text, lang='en' ,slow = 'False')\n",
    "    tts.write_to_fp(sound_file)\n",
    "    st.sidebar.audio(sound_file)\n",
    "    st.sidebar.markdown(\n",
    "    \"\"\"\n",
    "    ### Steps:\n",
    "    1. Upload PDF File\n",
    "    2. Enter Your Secret Key for Embeddings\n",
    "    3. Perform Q&A\n",
    "\n",
    "    **Note : File content and API key not stored in any form.**\n",
    "    \"\"\"\n",
    "    )\n",
    "    # Allow the user to upload a PDF file\n",
    "    uploaded_file = st.file_uploader(\"**Upload Your PDF File**\", type=[\"pdf\"])\n",
    "    if uploaded_file:\n",
    "        name_of_file = uploaded_file.name\n",
    "        doc = parse_pdf(uploaded_file)\n",
    "        pages = text_to_docs(doc)\n",
    "        if pages:\n",
    "            # Allow the user to select a page and view its content\n",
    "            with st.expander(\"Show Page Content\", expanded=False):\n",
    "                page_sel = st.number_input(\n",
    "                    label=\"Select Page\", min_value=1, max_value=len(pages), step=1\n",
    "                )\n",
    "                pages[page_sel - 1]\n",
    "            # Allow the user to enter an OpenAI API key\n",
    "            api = st.text_input(\n",
    "                \"**Enter OpenAI API Key**\",\n",
    "                type=\"password\",\n",
    "                placeholder=\"sk-\",\n",
    "                help=\"https://platform.openai.com/account/api-keys\",\n",
    "            )\n",
    "            \n",
    "            if api:\n",
    "                # Test the embeddings and save the index in a vector database\n",
    "                index = test_embed()\n",
    "                # Set up the question-answering system\n",
    "                qa = RetrievalQA.from_chain_type(\n",
    "                    llm=OpenAI(openai_api_key=api),\n",
    "                    chain_type = \"map_reduce\",\n",
    "                    retriever=index.as_retriever(),\n",
    "                )\n",
    "                st.session_state.api = api\n",
    "                # Set up the conversational agent\n",
    "                tools = [\n",
    "                    Tool(\n",
    "                        name=\"State of Union QA System\",\n",
    "                        func=qa.run,\n",
    "                        description=\"Useful for when you need to answer questions about the aspects asked. Input may be a partial or fully formed question.\",\n",
    "                    )\n",
    "                ]\n",
    "                prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can based on the context and memory available. \n",
    "                            You have access to a single tool:\"\"\"\n",
    "                suffix = \"\"\"Begin!\"\n",
    "\n",
    "                {chat_history}\n",
    "                Question: {input}\n",
    "                {agent_scratchpad}\"\"\"\n",
    "\n",
    "                prompt = ZeroShotAgent.create_prompt(\n",
    "                    tools,\n",
    "                    prefix=prefix,\n",
    "                    suffix=suffix,\n",
    "                    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    "                )\n",
    "\n",
    "                if \"memory\" not in st.session_state:\n",
    "                    st.session_state.memory = ConversationBufferMemory(\n",
    "                        memory_key=\"chat_history\"\n",
    "                    )\n",
    "\n",
    "                llm_chain = LLMChain(\n",
    "                    llm=OpenAI(\n",
    "                        temperature=0, openai_api_key=api, model_name=\"gpt-3.5-turbo\"\n",
    "                    ),\n",
    "                    prompt=prompt,\n",
    "                )\n",
    "                agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "                agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "                    agent=agent, tools=tools, verbose=True, memory=st.session_state.memory\n",
    "                )\n",
    "\n",
    "                # Allow the user to enter a query and generate a response\n",
    "                query = st.text_input(\n",
    "                    \"**What's on your mind?**\",\n",
    "                    placeholder=\"Hello I am your Training Assistant! . Ask me anything from {}\".format(name_of_file),\n",
    "                )\n",
    "\n",
    "                if query:\n",
    "                    with st.spinner(\n",
    "                        \"Generating Answer to your Query : `{}` \".format(query)\n",
    "                    ):\n",
    "                        res = agent_chain.run(query)\n",
    "                        st.info(res, icon=\"ðŸ¤–\")\n",
    "                        sound_file = BytesIO()\n",
    "                        tts = gTTS(res, lang='en')\n",
    "                        tts.write_to_fp(sound_file)\n",
    "                        st.audio(sound_file)\n",
    "\n",
    "                # Allow the user to view the conversation history and other information stored in the agent's memory\n",
    "                with st.expander(\"History/Memory\"):\n",
    "                    st.session_state.memory\n",
    "\n",
    "else :\n",
    "    st.title(\"Simulator : Course Correction\")\n",
    "    # Define the options for the radio button\n",
    "    options = ('Prediction','Recommendation','Sensitivity Analysis')\n",
    "\n",
    "    # Initialize the selected option\n",
    "    selected_option = st.session_state.page_selection if 'page_selection' in st.session_state else options[0]\n",
    "\n",
    "    # Create the radio button with a horizontal layout\n",
    "    selected_option = st.radio(\"\", options, index=options.index(selected_option),horizontal=True, \n",
    "                               key=\"navigation\", format_func=lambda x: x, help=\"Page Navigation\")\n",
    "    # Store the selected option in session state\n",
    "    st.session_state.page_selection = selected_option\n",
    "    # Show the corresponding page based on the selection\n",
    "    if selected_option == 'Sensitivity Analysis':\n",
    "        st.title(\"Sensitivity Analysis\")\n",
    "        \n",
    "        st.subheader(\"Controllable Parameters\")\n",
    "        # First row with four columns\n",
    "        col1_row1, col2_row1, col3_row1, col4_row1,col5_row1 = st.columns(5)\n",
    "        with col1_row1:\n",
    "            input_steam_inlet_temp = st.slider('Steam In Temp(C)' ,min_value = 147 , max_value = 153)\n",
    "        with col2_row1:\n",
    "            input_steam_outlet_temp = st.slider('Steam Out Temp(C)' ,min_value = 136 , max_value = 145)\n",
    "        with col3_row1:\n",
    "            input_steam_sep_line_temp = st.slider( 'Steam Sep(C)' ,min_value = 115 , max_value = 125)    \n",
    "        with col4_row1:\n",
    "            input_transfer_cool_air_temp = st.slider('Cooling Air(C)' ,min_value = 63 , max_value = 125)\n",
    "        with col5_row1:\n",
    "            input_transfer_air = st.slider('Transfer Air(C)' ,min_value = 40 , max_value = 125)\n",
    "            \n",
    "        st.subheader(\"External Parameters\")\n",
    "        col1_row3, col2_row3  = st.columns(2)\n",
    "        with col1_row3:\n",
    "            ambient_temp= st.slider('Ambient Temp(F)' ,min_value = 10 , max_value = 60)  \n",
    "        with col2_row3:\n",
    "            ambient_humidity = st.slider('Ambient Humidity(%) ' ,min_value = 10 , max_value = 60)\n",
    "            \n",
    "        st.subheader(\"Raw Material Properties\")\n",
    "        col1_row4, col2_row4 , col3_row4 , col4_row4 ,col5_row4 = st.columns(5)\n",
    "        with col1_row4:\n",
    "            LOD_raw = st.slider('Raw Husk LOD %' ,min_value = 5 , max_value = 15)    \n",
    "        with col2_row4:\n",
    "            Swell_vol = st.slider('Swell Volume (ml)' ,min_value = 23 , max_value = 35)\n",
    "            # Add your content for Column 2\n",
    "        with col3_row4:\n",
    "            on_30 = st.slider( '% on 30 mesh' ,min_value = 23 , max_value = 60)        \n",
    "        with col4_row4:\n",
    "            thru_70 = st.slider( '% thru 70' ,min_value = 0 , max_value = 7)     \n",
    "        with col5_row4:\n",
    "            thru_100 = st.slider( '% thru 100' ,min_value = 0 , max_value = 2)\n",
    "            \n",
    "        st.subheader(\"Other Parameters\")\n",
    "        col1_row2, col2_row2 , col3_row2 = st.columns(3)\n",
    "        with col1_row2:\n",
    "            feed_rate = st.slider( 'Feed Rate (kg/hr)' ,min_value = 1000 , max_value = 2000)\n",
    "        with col2_row2:\n",
    "            air_velocity = st.slider('Steam Velocity (m/s)' ,min_value = 29 , max_value = 32)   \n",
    "        with col3_row2:\n",
    "            steam_pressure = st.slider('Steam Pressure (bar)' ,min_value = 2.6 , max_value = 2.8)\n",
    "   \n",
    "        input_data_ = pd.DataFrame({\n",
    "        'Air Velocity': [float(air_velocity)],\n",
    "        'Steam Inlet Temp': [float(input_steam_inlet_temp)],\n",
    "        'Steam Outlet Temp': [float(input_steam_outlet_temp)],\n",
    "        'Steam Sep Line Temp': [float(input_steam_sep_line_temp)],\n",
    "        'Transfer cool air temp':[float(input_transfer_cool_air_temp)],\n",
    "        'Steam Pressure': [float(steam_pressure)],\n",
    "        'Ambient Temp': [float(ambient_temp)],\n",
    "        'Ambient Humidity':[float(ambient_humidity)],\n",
    "        'Feed_rate':[float(feed_rate)],\n",
    "        'LOD_raw':[float(LOD_raw)],\n",
    "        'Swell_vol':[float(Swell_vol)],\n",
    "        'on_30':[float(on_30)],\n",
    "        'thru_70':[float(thru_70)],\n",
    "        'thru_100':[float(thru_100)],\n",
    "        'Transfer Air':[float(input_transfer_air)]})\n",
    "    \n",
    "        input_data_['const']=1\n",
    "        #predicted_moisture_content = np.dot(input_data_, np.append(coefficients,[intercept]))\n",
    "        # Display the predictions\n",
    "        st.sidebar.subheader(\"Output %\")\n",
    "        predicted_moisture_content = np.dot(input_data_, np.append(coefficients,[intercept]))\n",
    "        # Display the predictions\n",
    "        styled_text = f\"<span style='font-weight:bold;color:green'>{round(predicted_moisture_content[0],6):.2f}%</span>\"\n",
    "        st.sidebar.markdown(styled_text, unsafe_allow_html=True)\n",
    "        with col1_row1:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df,'Steam Inlet Temp')\n",
    "        with col2_row1:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df,'Steam Outlet Temp')\n",
    "        with col3_row1:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df,'Steam Sep Line Temp')\n",
    "        with col4_row1:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df,'Transfer cool air temp')\n",
    "        with col5_row1:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df,'Transfer Air')\n",
    "        with col1_row2:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df_,'Feed_rate')\n",
    "        with col2_row2:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df_,'Air Velocity')\n",
    "        with col3_row2:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df_,'Steam Pressure')\n",
    "        with col1_row3:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df_,'Ambient Temp')\n",
    "        with col2_row3:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df_,'Ambient Humidity')\n",
    "        with col1_row4:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df_,'LOD_raw')\n",
    "        with col2_row4:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df_,'Swell_vol')\n",
    "        with col3_row4:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df_,'on_30')\n",
    "        with col4_row4:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df_,'thru_70')\n",
    "        with col5_row4:\n",
    "            sensitivity_graph(data,input_data_,coefficients,intercept,ub_lb_df_,'thru_100')\n",
    "            \n",
    "    elif selected_option == 'Prediction':\n",
    "        # Create a Streamlit web app\n",
    "        st.title(\"Prediction\")\n",
    "        # Upload manufacturing image\n",
    "        image = Image.open(r\"C:\\Users\\Harshita.Saxena\\Downloads\\png_test\\test\\manufacturing_img.jpeg\") #read img\n",
    "        st.image(image, use_column_width=True)\n",
    "        st.subheader(\"Controllable Parameters\")\n",
    "        # User input for the controllable independent variables\n",
    "        col1 , col2 , col3 , col4 , col5 = st.columns(5) \n",
    "        with col1:\n",
    "            input_steam_inlet_temp = st.number_input(\"Steam In Temp (C): \" , value = 153)\n",
    "            alerts(float(input_steam_inlet_temp),147,153)\n",
    "        with col2:\n",
    "            input_steam_outlet_temp = st.number_input(\"Steam Out Temp (C): \",value = 145)\n",
    "            alerts(float(input_steam_outlet_temp),136,145)\n",
    "        with col3:\n",
    "            input_steam_sep_line_temp = st.number_input(\"Steam Sep (C): \",value = 145)\n",
    "            alerts(float(input_steam_sep_line_temp),115,125)\n",
    "        with col4:\n",
    "            input_transfer_cool_air_temp = st.number_input(\"Cooling Air (C):\",value = 90)\n",
    "            alerts(float(input_transfer_cool_air_temp),63,125)\n",
    "        with col5:\n",
    "            input_transfer_air_temp = st.number_input(\"Transfer Air (C):\",value = 63)\n",
    "            alerts(float(input_transfer_cool_air_temp),40,125)\n",
    "        # Display subheading for external temperature\n",
    "        st.subheader(\"External Parameters\")\n",
    "        col1 , col2 = st.columns(2)\n",
    "        with col1:\n",
    "            input_ambient_temp = st.number_input(\"Ambient Temperature (F):\" , value = 90)\n",
    "        with col2:\n",
    "            ambient_humidity = st.number_input(\"Ambient Humidity (%):\" , value = 30)\n",
    "\n",
    "        st.subheader('Raw Material Properties')\n",
    "         #Display subheading for raw material characteristics\n",
    "        col1, col2 ,col3,col4,col5 = st.columns(5)\n",
    "        # Display the raw material charecteristics\n",
    "        with col1:\n",
    "            LOD_raw_husk = st.number_input(\"Raw Husk LOD%: \" , value = 9.6)\n",
    "        with col2:\n",
    "            swell = st.number_input(\"Swell Volume (ml) \" , value = 29.87)\n",
    "        with col3:\n",
    "            on_30 = st.number_input(\"% on 30 mesh: \" , value = 42.2)\n",
    "        with col4:\n",
    "            thru_70 = st.number_input(\"% thru 70 mesh: \" , value = 0.10)\n",
    "        with col5:\n",
    "            thru_100 = st.number_input(\" % thru 100 mesh: \" , value = 0.5)\n",
    "        st.subheader('Other Parameters')\n",
    "         #Display subheading for fixed input parameters\n",
    "        col1 , col2, col3 = st.columns(3)\n",
    "        with col1:\n",
    "            avg_feed_rate = st.number_input(\"Feed Rate (kg/hr): \" ,min_value= 1000,max_value=2000 , value = 1000)\n",
    "            alerts(float(avg_feed_rate),1000,2000)\n",
    "        with col2:\n",
    "            avg_steam_pressure = st.number_input(\"Steam Pressure (bar): \" , min_value=2.6 ,max_value=2.8 ,value = 2.6)\n",
    "            alerts(float(avg_steam_pressure),2.6,2.8)\n",
    "        with col3:\n",
    "            avg_air_velocity = st.number_input(\"Steam Velocity (m/s): \" ,min_value=29 ,max_value=32 , value = 29)\n",
    "            alerts(float(avg_air_velocity),29,32)\n",
    "        # Create a dataframe with the user input and fixed values\n",
    "        input_data_ = pd.DataFrame({\n",
    "            'Air Velocity': [float(avg_air_velocity)],\n",
    "            'Steam Inlet Temp': [float(input_steam_inlet_temp)],\n",
    "            'Steam Outlet Temp': [float(input_steam_outlet_temp)],\n",
    "            'Steam Sep Line Temp': [float(input_steam_sep_line_temp)],\n",
    "            'Transfer cool air temp':[float(input_transfer_cool_air_temp)],\n",
    "            'Steam Pressure': [float(avg_steam_pressure)],\n",
    "            'Ambient Temp': [float(input_ambient_temp)],\n",
    "            'Ambient Humidity':[float(ambient_humidity)],\n",
    "            'Feed_rate':[float(avg_feed_rate)],\n",
    "            'LOD_raw':[float(LOD_raw_husk)],\n",
    "            'Swell_vol':[float(swell)],\n",
    "            'on_30':[float(on_30)],\n",
    "            'thru_70':[float(thru_70)],\n",
    "            'thru_100':[float(thru_100)],\n",
    "            'Transfer Air':[float(input_transfer_air_temp)]\n",
    "        })\n",
    "        input_data_['const'] = 1.0 #sm.add_constant(input_data)\n",
    "        # Predict the moisture content using the trained model\n",
    "        # Display the predicted moisture content\n",
    "        if st.button('Run'):\n",
    "            st.subheader(\"Predicted Output %\")\n",
    "            predicted_moisture_content = np.dot(input_data_, np.append(coefficients,[intercept]))\n",
    "            # Display the predictions\n",
    "            styled_text = f\"<span style='font-weight:bold;color:green'>{round(predicted_moisture_content[0],2):.2f}%</span>\"\n",
    "            st.markdown(styled_text, unsafe_allow_html=True)\n",
    "        #st.write(round(predicted_moisture_content[0],5))\n",
    "            #st.write('You can optimize the output if it is not in desired range')\n",
    "            #alert_specif_range_max(input_max_LOD,7.6)\n",
    "        #st.session_state.number1 = predicted_moisture_content[0]\n",
    "        predicted_moisture_content = np.dot(input_data_, np.append(coefficients,[intercept]))\n",
    "        st.session_state['stored_np_array'] = predicted_moisture_content\n",
    "        st.session_state.dataframe = input_data_\n",
    "    else:            \n",
    "        st.title('Recommendation')\n",
    "        input_data_=st.session_state.dataframe\n",
    "        input_data_1=input_data_.iloc[0]\n",
    "        st.subheader('Parameter Summary')\n",
    "        st.write(\"You can edit the Parameters on the Prediction Screen\")\n",
    "        st.subheader(\"Controllable Parameters\")\n",
    "        # User input for the controllable independent variables\n",
    "        col1 , col2 , col3 , col4 , col5 = st.columns(5) \n",
    "        with col1:\n",
    "            st.write(\"Steam In Temp (C): \" ,input_data_1['Steam Inlet Temp'])\n",
    "        with col2:\n",
    "            st.write(\"Steam Out Temp (C): \",input_data_1['Steam Outlet Temp'])\n",
    "        with col3:\n",
    "            st.write(\"Steam Sep (C): \",input_data_1['Steam Sep Line Temp'])\n",
    "        with col4:\n",
    "            st.write(\"Cooling Air (C):\",input_data_1['Transfer cool air temp'])\n",
    "        with col5:\n",
    "            st.write(\"Transfer Air (C):\",input_data_1['Transfer Air'])\n",
    "        # Display subheading for external temperature\n",
    "        st.subheader(\"External Parameters\")\n",
    "        col1 , col2 = st.columns(2)\n",
    "        with col1:\n",
    "            st.write(\"Ambient Temperature (F):\" , input_data_1['Ambient Temp'])\n",
    "        with col2:\n",
    "            st.write(\"Ambient Humidity (%):\" , input_data_1['Ambient Humidity'])\n",
    "\n",
    "        st.subheader('Raw Material Properties')\n",
    "         #Display subheading for raw material characteristics\n",
    "        col1, col2 ,col3,col4,col5 = st.columns(5)\n",
    "        # Display the raw material charecteristics\n",
    "        with col1:\n",
    "            st.write(\"Raw Husk LOD%: \" , input_data_1['LOD_raw'])\n",
    "        with col2:\n",
    "            st.write(\"Swell Volume (m/l): \" , input_data_1['Swell_vol'])\n",
    "        with col3:\n",
    "            st.write(\"% on 30 mesh: \" , input_data_1['on_30'])\n",
    "        with col4:\n",
    "            st.write(\"% thru 70 mesh: \" , input_data_1['thru_70'])\n",
    "        with col5:\n",
    "            st.write(\" % thru 100 mesh: \" , input_data_1['thru_100'])\n",
    "        st.subheader('Other Parameters')\n",
    "         #Display subheading for fixed input parameters\n",
    "        col1 , col2, col3 = st.columns(3)\n",
    "        with col1:\n",
    "            st.write(\"Feed Rate (kg/hr): \" ,input_data_1['Feed_rate'])\n",
    "        with col2:\n",
    "             st.write(\"Steam Pressure (bar): \" , input_data_1['Steam Pressure'])\n",
    "        with col3:\n",
    "            st.write(\"Steam Velocity (m/s): \" ,input_data_1['Air Velocity'])\n",
    "        \n",
    "        col1 , col2 ,col3 =st.columns([3,1,1])\n",
    "        with col1:\n",
    "            st.subheader('Predicted Output ')\n",
    "            predicted_moisture_content= st.session_state.get('stored_np_array', np.array([]))\n",
    "            #predicted_moisture_content = np.dot(input_data_, np.append(coefficients,[intercept]))\n",
    "             # Display the predictions\n",
    "            styled_text = f\"<span style='font-weight:bold;color:green'>{round(predicted_moisture_content[0],2):.2f}%</span>\"\n",
    "            st.markdown(styled_text, unsafe_allow_html=True)\n",
    "        with col2:\n",
    "            input_min_LOD = float(st.number_input(\"Minimum  % :\",value = 5))\n",
    "            #alerts(input_min_LOD,3.9,7.6)\n",
    "        with col3:\n",
    "            input_max_LOD = float(st.number_input(\"Maximum %:\",value = 8))\n",
    "            #alerts(input_max_LOD,3.9,7.6)\n",
    "        st.write('You can Optimize the output if it is not in the desired range')\n",
    "        if st.button('Run and Optimize'):\n",
    "        # Button for issue input parameter recommendations\n",
    "            if ((predicted_moisture_content[0] < input_min_LOD)|(predicted_moisture_content[0] > input_max_LOD)):\n",
    "                recc_df , recc_all = reccomendation_generator(input_data_,ub_lb_df,coefficients,intercept,predicted_moisture_content,input_min_LOD,input_max_LOD)\n",
    "                recc_df = format_excel(recc_df)\n",
    "                selected_columns= ['Steam In Temp (C)','Steam Out Temp (C)','Steam Sep (C)',\n",
    "                   'Cooling Air (C)','Transfer Air (C)']\n",
    "                \n",
    "                recc_df = recc_df.round(decimals=2)\n",
    "                # Apply the style to the DataFrame for each selected column\n",
    "                \n",
    "                #styled_df = recc_df.style.apply(highlight_cells, selected_columns=selected_columns, axis=1)\n",
    "                recc_all_ = format_excel(recc_all)\n",
    "                recc_all_ = recc_all_.round(decimals =2)\n",
    "                recc_all_['Iteration']=recc_all_['Iteration'].astype(int)\n",
    "                st.write(\"Recommendation: Adjust the controllable input parameters to bring LOD within the target range given bounds on parameters\")\n",
    "                st.dataframe(recc_df.set_index(recc_df.columns[0]))\n",
    "                \n",
    "                st.write(\"Maximum Iterations Reached\")\n",
    "                if ((recc_all_['Updated LOD % '].iloc[-1]>input_max_LOD)|(recc_all_['Updated LOD % '].iloc[-1]<input_min_LOD)):\n",
    "                    st.error('Convergence to range cannot be attained given Target Ranges for Parameters')\n",
    "                else:\n",
    "                    st.success('Convergence to Target Range attained')\n",
    "                # Add a download button\n",
    "                csv = recc_all_.to_csv(index=False)\n",
    "                b64 = base64.b64encode(csv.encode()).decode()\n",
    "                href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"output.csv\">Download CSV File</a>'\n",
    "                st.markdown(href, unsafe_allow_html=True)\n",
    "                os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "                if 'prompts' not in st.session_state:\n",
    "                    st.session_state.prompts = []\n",
    "                if 'responses' not in st.session_state:\n",
    "                    st.session_state.responses = []\n",
    "                def send_click():\n",
    "                    if st.session_state.user != '':\n",
    "                        prompt = st.session_state.user\n",
    "                        response = agent.run(prompt)\n",
    "                        sound_file = BytesIO()\n",
    "                        tts = gTTS(response, lang='en',slow = False)\n",
    "                        tts.write_to_fp(sound_file)\n",
    "                        st.audio(sound_file)\n",
    "                        st.session_state.prompts.append(prompt)\n",
    "                        st.session_state.responses.append(response)\n",
    "                chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "                agent = create_pandas_dataframe_agent(chat, recc_all_, verbose=True)\n",
    "                st.text_input(\"Ask Something:\", key=\"user\")\n",
    "                st.button(\"Send\", on_click=send_click)\n",
    "                if st.session_state.prompts:\n",
    "                    for i in range(len(st.session_state.responses)-1, -1, -1):\n",
    "                        message(st.session_state.responses[i], key=str(i), seed='Milo')\n",
    "                        message(st.session_state.prompts[i], is_user=True, key=str(i) + '_user', seed=83)\n",
    "            else:\n",
    "                st.write('No reccomendation required')                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf076d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
